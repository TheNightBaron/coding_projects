{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyFolder(path):\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        os.remove(path + '\\\\' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utility functions before-hand\n",
    "#reshaping the photos to have minimum dimension of 400 while maintaining the aspect ratio\n",
    "\n",
    "def shaping(size):\n",
    "    if size[0]<size[1]:\n",
    "        size[1] = int(400*size[1]/size[0])\n",
    "        size[0] = 400\n",
    "    else:\n",
    "        size[0] = int(400*size[0]/size[1])\n",
    "        size[1] = 400\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the image in case I want to see it\n",
    "\n",
    "def displayImage(photo):\n",
    "    cv2.imshow('image', photo)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rescaling factor to rescale original photo to extract a 224x224 face\n",
    "def getFactors(faceList):\n",
    "    factors = []\n",
    "    for x in range(len(faces)):\n",
    "        factors.append(224/faces[x][2])\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlargedFacesTen(x_coordinate, y_coordinate, width, height, imageShape):\n",
    "    #check if width can be increased in left direction\n",
    "    if x_coordinate - (0.1*width) > -1: new_x_coordinate = int(x_coordinate - (0.1*width))\n",
    "    else: return x_coordinate, y_coordinate, width, height\n",
    "    #check if height can be increased in left direction\n",
    "    if y_coordinate - (0.1*height) > -1: new_y_coordinate = int(y_coordinate - (0.1*height))\n",
    "    else: return x_coordinate, y_coordinate, width, height\n",
    "    #check if width can be increased in right direction\n",
    "    if x_coordinate + (1.1*width) < imageShape[1]+1: new_width = int(1.2*width)\n",
    "    else: return x_coordinate, y_coordinate, width, height\n",
    "    #check if height can be increased in right direction\n",
    "    if y_coordinate + (1.1*height) < imageShape[0]+1: new_height = int(1.2*height)\n",
    "    else: return x_coordinate, y_coordinate, width, height\n",
    "    \n",
    "    return new_x_coordinate, new_y_coordinate, new_width, new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlargedFacesTwenty(x_coordinate, y_coordinate, width, height, imageShape):\n",
    "    #check if width can be increased in left direction\n",
    "    if x_coordinate - (0.2*width) > -1: new_x_coordinate = int(x_coordinate - (0.2*width))\n",
    "    else: return enlargedFacesTen(x_coordinate, y_coordinate, width, height, imageShape)\n",
    "    #check if height can be increased in left direction\n",
    "    if y_coordinate - (0.2*height) > -1: new_y_coordinate = int(y_coordinate - (0.2*height))\n",
    "    else: return enlargedFacesTen(x_coordinate, y_coordinate, width, height, imageShape)\n",
    "    #check if width can be increased in right direction\n",
    "    if x_coordinate + (1.2*width) < imageShape[1]+1: new_width = int(1.4*width)\n",
    "    else: return enlargedFacesTen(x_coordinate, y_coordinate, width, height, imageShape)\n",
    "    #check if height can be increased in right direction\n",
    "    if y_coordinate + (1.2*height) < imageShape[0]+1: new_height = int(1.4*height)\n",
    "    else: return enlargedFacesTen(x_coordinate, y_coordinate, width, height, imageShape)\n",
    "    \n",
    "    return new_x_coordinate, new_y_coordinate, new_width, new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveScaledFaces(faceList, factors, colourImage, grayImage, imageShape, savePath):\n",
    "    for x in range(len(factors)):\n",
    "        newShape = [int(i*factors[x]) for i in imageShape]\n",
    "        scaledGray = cv2.resize(grayImage, tuple(newShape))\n",
    "        scaledColour = cv2.resize(colourImage, tuple(newShape))\n",
    "        scaledFace = [int(i*factors[x]) for i in faceList[x]]\n",
    "        for (ax, y, w, h) in [scaledFace]:\n",
    "            #cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 1)\n",
    "            cv2.imwrite(savePath + '\\\\' + str(ax) + str(y) + str(w) + str(h) + '_face.jpg', scaledColour[y:y+h, ax:ax+w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of cv2 to get haar cascades\n",
    "\n",
    "#cv2.__file__\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('C:\\\\Anaconda\\\\lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\Harsh Garg\\\\Pictures\\\\Model\\\\F'\n",
    "photos = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image and convert it to greyscale\n",
    "for pics in photos:\n",
    "    try:\n",
    "        image = cv2.imread(path+'\\\\'+pics)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #apparently image width and height are interchanged when it is read, so I manually changed it to the correct one\n",
    "\n",
    "        shape = [np.shape(gray.T)[0],np.shape(gray.T)[1]]\n",
    "\n",
    "        #calculate shape of the image if it has to be 400 x (400*aspect ratio)\n",
    "\n",
    "        shape = shaping(shape)\n",
    "\n",
    "        #resize gray and colour images\n",
    "\n",
    "        newGray = cv2.resize(gray, tuple(shape))\n",
    "\n",
    "        newImage = cv2.resize(image, tuple(shape))\n",
    "\n",
    "        # Detect faces in the resized image\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            newGray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=3,\n",
    "            minSize=(30, 30),\n",
    "            )\n",
    "        if len(faces)!=0:\n",
    "            enlargedFaces = []\n",
    "            for x,y,w,h in faces:\n",
    "                enlargedFaces.append(list(enlargedFacesTwenty(x,y,w,h,shape)))  \n",
    "            newFactors = getFactors(enlargedFaces)\n",
    "            saveScaledFaces(enlargedFaces, newFactors, image, gray, shape, 'D:\\\\Harsh Garg\\\\Pictures\\\\Detected Faces')\n",
    "        else: pass\n",
    "    except: pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
